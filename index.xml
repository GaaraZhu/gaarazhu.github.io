<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gary&#39;s Blog</title>
    <link>https://GaaraZhu.github.io/</link>
    <description>Recent content on Gary&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>sec.gary@gmail.com (GaryZhu)</managingEditor>
    <webMaster>sec.gary@gmail.com (GaryZhu)</webMaster>
    <lastBuildDate>Sat, 02 Apr 2022 11:09:48 +1300</lastBuildDate><atom:link href="https://GaaraZhu.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chat the Ops up</title>
      <link>https://GaaraZhu.github.io/chat-the-ops-up/</link>
      <pubDate>Sat, 02 Apr 2022 11:09:48 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/chat-the-ops-up/</guid>
      <description>TL;DR 
This is the story of how we improved our CI/CD methodology by using Bamboo-on-Teams, a serverless ChatOps tool for interacting with Atlassian Bamboo from Microsoft Teams.</description>
    </item>
    
    <item>
      <title>Fine-grained authorization with Amazon Cognito user pool and API Gateway</title>
      <link>https://GaaraZhu.github.io/fine-grained-access-control-with-cognito/</link>
      <pubDate>Sat, 02 Apr 2022 11:09:48 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/fine-grained-access-control-with-cognito/</guid>
      <description>Shifting from monolith architecture to microservices are full of challenges where one primary is how to manage security and access control properly. As each microservice is running indenpendly and communicates with each other to perform a specific function, we need to authenticate the incoming request to ensures that it comes from a legitimate service.</description>
    </item>
    
    <item>
      <title>AWS one punch</title>
      <link>https://GaaraZhu.github.io/aws-one-punch/</link>
      <pubDate>Sun, 19 Dec 2021 10:21:44 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/aws-one-punch/</guid>
      <description>Background 
There was a time when I was working on a feature which required changes to more than ten microservices. In the dev testing stage I got all the services up running in the cloud by applying Cloudformation changes from local.</description>
    </item>
    
    <item>
      <title>Tail call optimization in Scala</title>
      <link>https://GaaraZhu.github.io/tail-call-optimization/</link>
      <pubDate>Fri, 02 Oct 2015 15:29:15 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/tail-call-optimization/</guid>
      <description>Recursion provides us an easy way to solve some problems, and makes the code simpler and easier to follow. But one problem of it is the memory cost caused by the recursive call stack, which could be critical for memory sensitive applications like mobile ones.</description>
    </item>
    
    <item>
      <title>Mysql读写分离：Spring&#43;JPA应用层实现 vs Amoeba中间件实现</title>
      <link>https://GaaraZhu.github.io/read-write-split/</link>
      <pubDate>Sat, 05 Jan 2013 21:08:12 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/read-write-split/</guid>
      <description>背景 
前段时间看了篇文章，讲Youku网数据库架构的演变，如何从最开始的读写分离，再到垂直分区，最后到水平分片，一步一步慢慢成熟的。看完之后很有冲动抽出一个模型来把这几种技术都实现一下。说干就干，首先是读写分离。
 实现方案 
我使用的数据库是Mysql，主从数据复制用的是半同步机制(mysql版本必须 5.5以上)，具体配置，可以参照这篇文章： http://blog.csdn.net/changerlove/article/details/6167255， 要注意Windows环境下，mysql配置文件为my.ini, linux下才是my.cnf。
然后主从复制有两类做法，一类就是在应用层去动态切换数据源，最简单的做法就是根据事务类型来做Route，另外一类就是利用所谓的“中间件”，在应用层和数据源之间通过分析SQL来Route，目前可选的“中间件有Mysql自带的Mysql Proxy还有阿里开发的Amoeba，后者据说比Mysql Proxy更稳定，使用也更简单，所以“中间件”做法里我选了第二种来尝试，待会儿会分析Amoeba的优劣，这儿先讲第一种做法，在应用层实现读写分离。
 Spring+JPA应用层实现读写分离  实现 
在例子中有两台Mysql Server，一台Master 负责写，一台Slave负责读，对应的JPA 配置文件如下：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?</description>
    </item>
    
    <item>
      <title>MapReduce tuning</title>
      <link>https://GaaraZhu.github.io/map-reduce-tunning/</link>
      <pubDate>Sun, 23 Dec 2012 01:33:45 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/map-reduce-tunning/</guid>
      <description>Backgroup MapReduce is not a low latency computing model, minutes at least will go before we got the result. But this does not mean there&amp;rsquo;s no way for us to make it faster.</description>
    </item>
    
    <item>
      <title>基于Sqoop和Hadoop的数据质量分析报告</title>
      <link>https://GaaraZhu.github.io/sqoop/</link>
      <pubDate>Thu, 15 Nov 2012 23:14:41 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/sqoop/</guid>
      <description>背景  一个系统的数据质量不高通常是软件本身做的不够好，数据从源头就出现了问题。为了能够持续归总interface数据质量报告，来完善系统流程，我们就需要定量定性的分析源头数据。
 现状及问题  首先，我们为了能够更好的support产品issue，上游系统的消息以及处理之后的回馈信息，都会被保存在关系数据库里，对于我们来说，可以简单分析处理后的回馈信息，按照消息类型，消息源系统来分类，解析message，抽取error code，最后归总报告。
流程很清晰，但是落实到代码，如果简单利用cursor一行行读出来处理的话，效率肯定极其低下，怎么办？ 并行计算！可以利用MapReduce来处理。但是我们应该如何将保存在Oracle中Message导入Hadoop的HDFS中呢？
 解决方案  Sqoop ! Sqoop 是一个开源框架，用来实现Hadoop和关系数据库之间的数据迁移，使用截图如下
从执行数据迁移时的截图可以看出Sqoop本身也是基于MapReduce设计的，所以他支持并行导入/导出数据，更为给力的是，在导入条件里，你可以用SQL来进行数据过滤，只导入/导出你关心的行或者列。但是Sqoop在大数据量迁移的时候性能不是很好，尤其在Oracle和Hadoop之间，不过不用担心，我们可以使用开源插件来提升Sqoop数据迁移性能，比如Quest Connector。其实Oracle本身也有类似的插件，但是：
 它只支持从Hadoop到Oracle的数据迁移 它不是免费的   在数据被正确导入到HDFS之后，我们就可以开始编写MapReduce函数了，首先在map函数里根据消息类型，case by case的进行text -&amp;gt;xml object的转换，然后截取反馈信息（error code），接着在reduce函数里面按照源系统进行分区，汇总，最后再利用Sqoop导入Oracle。</description>
    </item>
    
    <item>
      <title>Java深度克隆</title>
      <link>https://GaaraZhu.github.io/deep-clone/</link>
      <pubDate>Fri, 28 Sep 2012 08:33:51 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/deep-clone/</guid>
      <description>背景  在实际开发中经常遇到属性克隆的问题，比如在表现层提交的Request DTO，可能需要在控制层被映射成多个Java Bean，再传递到逻辑层来进行相应的业务处理，那么如何才能简单而又快速的完成属性克隆呢？
对于仅仅包含简单属性的Java Bean来说，Apache Commons里的BeanUtils 是个不错的选择，不过前提是对应属性必须具备相同的属性名。但是对于复杂属性来说， 如果两个属性的类型不同，或者类型参数不同，使用BeanUtils的时候都要格外小心。
举个例子： InvoiceDTO和InvoiceBean里面都有两个属性amount和charges，类型定义如下：
InvoiceDTO [ amount -&amp;gt; AmountDTO, charges -&amp;gt; List&amp;lt;ChargeDTO&amp;gt;] InvoiceBean [ amount -&amp;gt;AmountBean, charges -&amp;gt; List&amp;lt;ChargeBean&amp;gt;] 这种情况下Apache BeanUtils无法正确克隆amount和charges，那我们应该怎么办呢？</description>
    </item>
    
    <item>
      <title>用MapReduce来进行用户行为分析</title>
      <link>https://GaaraZhu.github.io/analysis-user-behaviour/</link>
      <pubDate>Sun, 16 Sep 2012 01:26:10 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/analysis-user-behaviour/</guid>
      <description>背景 
在系统设计的时候，为了提高可用性，经常需要对用户行为进行分析，来持续完善系统。 一个典型的场景就是分析用户的查询条件，根据操作习惯和规律来精简用户输入，让查询变得更简单更高效。那么对于这种场景，我们应该如何实现？
 解决方案 
最简单的做法就是在每次查询的时候都把所用到的条件直接save到关系数据库，这种做法确实很简单，但是每次都需要做write操作，尤其对于操作密集型应用，我们不认为这是种很好的practise。或许你会说，可以做个内存队列，把信息缓存起来，然后batch write，这种做法性能确实比前一种更高效，而且对于统计用户使用信息这种场景，就算由于系统宕机导致的部分数据丢失，似乎也不会产生蝴蝶效应，但是我们总是想做得更好，于是，对于系统重启之类的可预知情况，我们可以利用RMI动态提交掉缓存中的数据，但是对于不可预知的情况，又该怎么办呢？或许我们可以找到其他更好的方法。
比如，直接把信息写到log里，然后安排一个schedual job来定期分析log，提取出信息再save到数据库，但是如果log很大很多，分析起来会不会很慢？查看了IPS PRD上的log，一天的log大概有几百M左右，而liner的数据量是logistic的10倍，log信息也会大出好几倍。而且通常为了trouble shooting，我们会保存一定期限的log，之后便会做house keeping，所以如果想在log被清掉之前做分析的话，仅仅是ARP项目，我们面对的就可能是几十个 N G的log文件，直接用JAVA分析？答案是可以的，用NIO，那还有其他办法吗？MapReduce!
 MapReduce 
MapReduce的分布式并行计算，说白了就是利用笨办法来暴力解决问题，对于统计用户查询条件这种场景，我们可以看到log片段如下：
877994 [[ACTIVE] ExecuteThread: &amp;#39;1&amp;#39; for queue: &amp;#39;weblogic.</description>
    </item>
    
    <item>
      <title>基于Aviator的注解驱动验证框架</title>
      <link>https://GaaraZhu.github.io/aviator-validator/</link>
      <pubDate>Sat, 25 Aug 2012 09:20:14 +1300</pubDate>
      <author>sec.gary@gmail.com (GaryZhu)</author>
      <guid>https://GaaraZhu.github.io/aviator-validator/</guid>
      <description>背景 
程序开发过程中，在同一系统中层层之间数据传递或者是异构系统之间同步异步通信的时候，我们经常需要对Java Bean进行属性验证，来决定是否继续后续process，或者直接抛出error message。
 传统解决方案 
传统的做法，给每个验证场景加一个验证类，专门负责所有属性的验证，以及验证结果的校验和处理，这种做法最直白，但是不够灵活。第二种就是Java 6自带的验证框架 Bean validation, 用注解的形式来表达属性对应的约束，Bean validation在很大程度上提高了数据验证的灵活性和复用性，但是第一，个人感觉扩展比较麻烦，首先你需要自定义个注解来代表对应的约束，其次你必须新建一个验证器，最后你必须在注解类上做好两者的mapping，对于每种约束，都逃不开这三步；第二点，Bean validation只能完成bean中单一属性的验证，不支持跨属性验证。
 EasyValidation! 
第三种做法就是基于Aviator DIY的验证框架EasyValidation，Aviator是淘宝开发的一款java表达式求值工具，感兴趣的朋友可以google一下。为了灵活性，和Bean validation一样，EasyValidation也是注解驱动的。我们认为所谓的约束其实就是一个结果为 true 或者 false 的表达式，所以首先把这些约束表达式加在属性上面作为元数据，然后通过反射去获取表达式，最后利用aviator去求值，再对结果做处理。</description>
    </item>
    
  </channel>
</rss>
